{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "#from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from numpy import concatenate\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in = 1, n_out = 1, dropnan = True):\n",
    "\t'''\n",
    "\tConvert series\n",
    "\tReturns:\n",
    "\tdataframe ready for supervised learning\n",
    "\t\n",
    "\t'''\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace = True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)   var1(t)\n",
      "1   0.848168   0.330645   0.000000  0.942408\n",
      "2   0.942408   0.362903   0.300214  0.958115\n",
      "3   0.958115   0.387097   0.600427  0.942408\n",
      "4   0.942408   0.564516   0.600427  0.958115\n",
      "5   0.958115   0.400538   0.600427  0.958115\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "dataset = pd.read_csv('Resampled_PF.csv', index_col = 0)\n",
    "dataset = dataset.drop(['Date'], axis = 1)\n",
    "values = dataset.values\n",
    "values = values.astype('float64')\n",
    "\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "\n",
    "# frame as supervised learning dataset\n",
    "#reframed = series_to_supervised(scaled, 1, 2)\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[4, 5]], axis = 1, inplace = True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5760, 1, 3) (5760,) (852, 1, 3) (852,)\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 240 * 24 #8months hourly data\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "\n",
    "# reshape input to 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape) #more hours (~5k) for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5760 samples, validate on 852 samples\n",
      "Epoch 1/100\n",
      "5760/5760 - 4s - loss: 0.9606 - val_loss: 0.9475\n",
      "Epoch 2/100\n",
      "5760/5760 - 0s - loss: 0.9079 - val_loss: 0.8966\n",
      "Epoch 3/100\n",
      "5760/5760 - 0s - loss: 0.8548 - val_loss: 0.8447\n",
      "Epoch 4/100\n",
      "5760/5760 - 0s - loss: 0.8003 - val_loss: 0.7909\n",
      "Epoch 5/100\n",
      "5760/5760 - 0s - loss: 0.7436 - val_loss: 0.7345\n",
      "Epoch 6/100\n",
      "5760/5760 - 0s - loss: 0.6837 - val_loss: 0.6745\n",
      "Epoch 7/100\n",
      "5760/5760 - 0s - loss: 0.6198 - val_loss: 0.6101\n",
      "Epoch 8/100\n",
      "5760/5760 - 0s - loss: 0.5508 - val_loss: 0.5403\n",
      "Epoch 9/100\n",
      "5760/5760 - 0s - loss: 0.4760 - val_loss: 0.4643\n",
      "Epoch 10/100\n",
      "5760/5760 - 0s - loss: 0.3945 - val_loss: 0.3814\n",
      "Epoch 11/100\n",
      "5760/5760 - 0s - loss: 0.3058 - val_loss: 0.2909\n",
      "Epoch 12/100\n",
      "5760/5760 - 0s - loss: 0.2098 - val_loss: 0.1925\n",
      "Epoch 13/100\n",
      "5760/5760 - 0s - loss: 0.1131 - val_loss: 0.0932\n",
      "Epoch 14/100\n",
      "5760/5760 - 0s - loss: 0.0575 - val_loss: 0.0496\n",
      "Epoch 15/100\n",
      "5760/5760 - 0s - loss: 0.0734 - val_loss: 0.0552\n",
      "Epoch 16/100\n",
      "5760/5760 - 0s - loss: 0.0795 - val_loss: 0.0496\n",
      "Epoch 17/100\n",
      "5760/5760 - 0s - loss: 0.0704 - val_loss: 0.0554\n",
      "Epoch 18/100\n",
      "5760/5760 - 0s - loss: 0.0642 - val_loss: 0.0682\n",
      "Epoch 19/100\n",
      "5760/5760 - 0s - loss: 0.0620 - val_loss: 0.0686\n",
      "Epoch 20/100\n",
      "5760/5760 - 0s - loss: 0.0599 - val_loss: 0.0626\n",
      "Epoch 21/100\n",
      "5760/5760 - 0s - loss: 0.0585 - val_loss: 0.0565\n",
      "Epoch 22/100\n",
      "5760/5760 - 0s - loss: 0.0586 - val_loss: 0.0540\n",
      "Epoch 23/100\n",
      "5760/5760 - 0s - loss: 0.0587 - val_loss: 0.0548\n",
      "Epoch 24/100\n",
      "5760/5760 - 0s - loss: 0.0579 - val_loss: 0.0555\n",
      "Epoch 25/100\n",
      "5760/5760 - 0s - loss: 0.0570 - val_loss: 0.0551\n",
      "Epoch 26/100\n",
      "5760/5760 - 0s - loss: 0.0562 - val_loss: 0.0537\n",
      "Epoch 27/100\n",
      "5760/5760 - 0s - loss: 0.0556 - val_loss: 0.0523\n",
      "Epoch 28/100\n",
      "5760/5760 - 0s - loss: 0.0550 - val_loss: 0.0511\n",
      "Epoch 29/100\n",
      "5760/5760 - 0s - loss: 0.0544 - val_loss: 0.0503\n",
      "Epoch 30/100\n",
      "5760/5760 - 0s - loss: 0.0538 - val_loss: 0.0497\n",
      "Epoch 31/100\n",
      "5760/5760 - 0s - loss: 0.0532 - val_loss: 0.0492\n",
      "Epoch 32/100\n",
      "5760/5760 - 0s - loss: 0.0525 - val_loss: 0.0485\n",
      "Epoch 33/100\n",
      "5760/5760 - 0s - loss: 0.0518 - val_loss: 0.0477\n",
      "Epoch 34/100\n",
      "5760/5760 - 0s - loss: 0.0512 - val_loss: 0.0468\n",
      "Epoch 35/100\n",
      "5760/5760 - 0s - loss: 0.0508 - val_loss: 0.0470\n",
      "Epoch 36/100\n",
      "5760/5760 - 0s - loss: 0.0500 - val_loss: 0.0464\n",
      "Epoch 37/100\n",
      "5760/5760 - 0s - loss: 0.0491 - val_loss: 0.0449\n",
      "Epoch 38/100\n",
      "5760/5760 - 0s - loss: 0.0485 - val_loss: 0.0434\n",
      "Epoch 39/100\n",
      "5760/5760 - 0s - loss: 0.0482 - val_loss: 0.0436\n",
      "Epoch 40/100\n",
      "5760/5760 - 0s - loss: 0.0474 - val_loss: 0.0432\n",
      "Epoch 41/100\n",
      "5760/5760 - 0s - loss: 0.0465 - val_loss: 0.0418\n",
      "Epoch 42/100\n",
      "5760/5760 - 0s - loss: 0.0459 - val_loss: 0.0403\n",
      "Epoch 43/100\n",
      "5760/5760 - 0s - loss: 0.0456 - val_loss: 0.0404\n",
      "Epoch 44/100\n",
      "5760/5760 - 0s - loss: 0.0448 - val_loss: 0.0399\n",
      "Epoch 45/100\n",
      "5760/5760 - 0s - loss: 0.0439 - val_loss: 0.0385\n",
      "Epoch 46/100\n",
      "5760/5760 - 0s - loss: 0.0433 - val_loss: 0.0372\n",
      "Epoch 47/100\n",
      "5760/5760 - 0s - loss: 0.0430 - val_loss: 0.0373\n",
      "Epoch 48/100\n",
      "5760/5760 - 0s - loss: 0.0422 - val_loss: 0.0369\n",
      "Epoch 49/100\n",
      "5760/5760 - 0s - loss: 0.0413 - val_loss: 0.0354\n",
      "Epoch 50/100\n",
      "5760/5760 - 0s - loss: 0.0409 - val_loss: 0.0351\n",
      "Epoch 51/100\n",
      "5760/5760 - 0s - loss: 0.0402 - val_loss: 0.0343\n",
      "Epoch 52/100\n",
      "5760/5760 - 0s - loss: 0.0394 - val_loss: 0.0326\n",
      "Epoch 53/100\n",
      "5760/5760 - 0s - loss: 0.0390 - val_loss: 0.0325\n",
      "Epoch 54/100\n",
      "5760/5760 - 0s - loss: 0.0383 - val_loss: 0.0318\n",
      "Epoch 55/100\n",
      "5760/5760 - 0s - loss: 0.0374 - val_loss: 0.0302\n",
      "Epoch 56/100\n",
      "5760/5760 - 0s - loss: 0.0371 - val_loss: 0.0302\n",
      "Epoch 57/100\n",
      "5760/5760 - 0s - loss: 0.0364 - val_loss: 0.0296\n",
      "Epoch 58/100\n",
      "5760/5760 - 0s - loss: 0.0355 - val_loss: 0.0281\n",
      "Epoch 59/100\n",
      "5760/5760 - 0s - loss: 0.0349 - val_loss: 0.0269\n",
      "Epoch 60/100\n",
      "5760/5760 - 0s - loss: 0.0346 - val_loss: 0.0274\n",
      "Epoch 61/100\n",
      "5760/5760 - 0s - loss: 0.0338 - val_loss: 0.0268\n",
      "Epoch 62/100\n",
      "5760/5760 - 0s - loss: 0.0328 - val_loss: 0.0250\n",
      "Epoch 63/100\n",
      "5760/5760 - 0s - loss: 0.0323 - val_loss: 0.0236\n",
      "Epoch 64/100\n",
      "5760/5760 - 0s - loss: 0.0321 - val_loss: 0.0243\n",
      "Epoch 65/100\n",
      "5760/5760 - 0s - loss: 0.0312 - val_loss: 0.0236\n",
      "Epoch 66/100\n",
      "5760/5760 - 0s - loss: 0.0302 - val_loss: 0.0216\n",
      "Epoch 67/100\n",
      "5760/5760 - 0s - loss: 0.0297 - val_loss: 0.0204\n",
      "Epoch 68/100\n",
      "5760/5760 - 0s - loss: 0.0293 - val_loss: 0.0202\n",
      "Epoch 69/100\n",
      "5760/5760 - 0s - loss: 0.0286 - val_loss: 0.0197\n",
      "Epoch 70/100\n",
      "5760/5760 - 0s - loss: 0.0278 - val_loss: 0.0186\n",
      "Epoch 71/100\n",
      "5760/5760 - 0s - loss: 0.0271 - val_loss: 0.0177\n",
      "Epoch 72/100\n",
      "5760/5760 - 0s - loss: 0.0266 - val_loss: 0.0171\n",
      "Epoch 73/100\n",
      "5760/5760 - 0s - loss: 0.0259 - val_loss: 0.0164\n",
      "Epoch 74/100\n",
      "5760/5760 - 0s - loss: 0.0252 - val_loss: 0.0155\n",
      "Epoch 75/100\n",
      "5760/5760 - 0s - loss: 0.0245 - val_loss: 0.0147\n",
      "Epoch 76/100\n",
      "5760/5760 - 0s - loss: 0.0239 - val_loss: 0.0141\n",
      "Epoch 77/100\n",
      "5760/5760 - 0s - loss: 0.0232 - val_loss: 0.0133\n",
      "Epoch 78/100\n",
      "5760/5760 - 0s - loss: 0.0226 - val_loss: 0.0125\n",
      "Epoch 79/100\n",
      "5760/5760 - 0s - loss: 0.0220 - val_loss: 0.0118\n",
      "Epoch 80/100\n",
      "5760/5760 - 0s - loss: 0.0214 - val_loss: 0.0111\n",
      "Epoch 81/100\n",
      "5760/5760 - 0s - loss: 0.0207 - val_loss: 0.0104\n",
      "Epoch 82/100\n",
      "5760/5760 - 0s - loss: 0.0201 - val_loss: 0.0097\n",
      "Epoch 83/100\n",
      "5760/5760 - 0s - loss: 0.0195 - val_loss: 0.0090\n",
      "Epoch 84/100\n",
      "5760/5760 - 0s - loss: 0.0189 - val_loss: 0.0083\n",
      "Epoch 85/100\n",
      "5760/5760 - 0s - loss: 0.0183 - val_loss: 0.0077\n",
      "Epoch 86/100\n",
      "5760/5760 - 0s - loss: 0.0177 - val_loss: 0.0071\n",
      "Epoch 87/100\n",
      "5760/5760 - 0s - loss: 0.0171 - val_loss: 0.0068\n",
      "Epoch 88/100\n",
      "5760/5760 - 0s - loss: 0.0165 - val_loss: 0.0065\n",
      "Epoch 89/100\n",
      "5760/5760 - 0s - loss: 0.0160 - val_loss: 0.0062\n",
      "Epoch 90/100\n",
      "5760/5760 - 0s - loss: 0.0155 - val_loss: 0.0057\n",
      "Epoch 91/100\n",
      "5760/5760 - 0s - loss: 0.0148 - val_loss: 0.0064\n",
      "Epoch 92/100\n",
      "5760/5760 - 0s - loss: 0.0152 - val_loss: 0.0058\n",
      "Epoch 93/100\n",
      "5760/5760 - 0s - loss: 0.0144 - val_loss: 0.0066\n",
      "Epoch 94/100\n",
      "5760/5760 - 0s - loss: 0.0157 - val_loss: 0.0086\n",
      "Epoch 95/100\n",
      "5760/5760 - 0s - loss: 0.0154 - val_loss: 0.0054\n",
      "Epoch 96/100\n",
      "5760/5760 - 0s - loss: 0.0153 - val_loss: 0.0060\n",
      "Epoch 97/100\n",
      "5760/5760 - 0s - loss: 0.0157 - val_loss: 0.0079\n",
      "Epoch 98/100\n",
      "5760/5760 - 0s - loss: 0.0175 - val_loss: 0.0067\n",
      "Epoch 99/100\n",
      "5760/5760 - 0s - loss: 0.0173 - val_loss: 0.0079\n",
      "Epoch 100/100\n",
      "5760/5760 - 0s - loss: 0.0167 - val_loss: 0.0063\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# design network: 50 neurons in the first hidden layer and 1 neuron in the output layer for prediction of power factor \n",
    "## line 1 (1 timestep with 3 features)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(50, input_shape = (train_X.shape[1], train_X.shape[2])))\n",
    "model.add(layers.Dense(1))\n",
    "model.compile(loss = 'mae', optimizer = 'adam') #MAE and adam version of SGD\n",
    "\n",
    "# fit network\n",
    "#history = model.fit(train_X, train_y, epochs = 50, batch_size = 72, validation_data = (test_X, test_y), verbose = 2, shuffle = False)\n",
    "history = model.fit(train_X, train_y, epochs = 100, batch_size = 1000, validation_data = (test_X, test_y), verbose = 2, shuffle = False)\n",
    "\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label = 'train')\n",
    "pyplot.plot(history.history['val_loss'], label = 'test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.002\n"
     ]
    }
   ],
   "source": [
    "##test loss if drops below training loss, the model may be overfitting the training data.\n",
    "\n",
    "\n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis = 1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:, 0]\n",
    "\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis = 1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:, 0]\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af8b93295ec152667600696eebafdfb1a6679e79e15871d01906b24cd0cc4b31"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
